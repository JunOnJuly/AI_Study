{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8df74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "%matplotlib inline\n",
    "%config lilineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419c4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a251319",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root='./data/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41a5bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "----------\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train)\n",
    "print(f'{\"-\"*10}')\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a75dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, drop_last=True)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e29595",
   "metadata": {},
   "source": [
    "# <font color='red'>DataLoader</font>\n",
    "* ## dataset\n",
    "    * dataset\n",
    "    * map-style dataset : index가 존재, \\_\\_getitem\\_\\_ 과 \\_\\_len\\_\\_ 선언 필요\n",
    "    * iterable-style dataset : \\_\\_iter\\_\\_ 선언 필요\n",
    "* ## batch_size\n",
    "    * int, optional, default=1\n",
    "    * batch 의 크기, tensor의 형태로 데이터가 반환, tensor로 변환이 안되는 데이터는 에러\n",
    "* ## shuffle\n",
    "    * bool, optional, default=false\n",
    "    * 데이터를 섞어 사용할지 결정, 실험 재현을 위해 torch.manual_seed 를 고정하기도 함\n",
    "* ## sampler\n",
    "    * sampler, optional\n",
    "    * index를 컨트롤하는 방법, 사용하기 위해서는 shuffle은 False, map-style에서 컨트롤 할때 사용\n",
    "        * sequetialSampler : 항상 같은 순서\n",
    "        * RandomSampler : 랜덤, replacement 여부 선택 가능, 개수 선택 가능\n",
    "        * SubsetRandomSampler : 랜덤 리스트\n",
    "        * WeightRandomSampler : 가중치에 따른 확률\n",
    "        * BatchSampler : batch 단위로 sampling 가능\n",
    "        * DistributedSampler : 분산처리\n",
    "* ## batch_sampler\n",
    "    * sampler와 거의 동일\n",
    "* ## num_workers\n",
    "    * int, optional, default=0\n",
    "    * 데이터 로딩에 사용되는 subprocess 수, default의 경우 main process로 데이터를 불러옴, 병목이 생길 수 있음\n",
    "* ## callate_fn\n",
    "    * callable, optional\n",
    "    * map-style 데이터셋에서 sample list를 batch 단위로 바꾸기 위해 사용\n",
    "* ## pin_memory\n",
    "    * bool, optional\n",
    "    * True 선언시, 데이터로더는 tensor 를 cuda 고정 메모리에 올림\n",
    "* ## drop_last\n",
    "    * bool, optional\n",
    "    * 마지막 남은 batch 를 drop\n",
    "    * batch 사이즈가 다를 경우 용이\n",
    "* ## time_out\n",
    "    * numeric, optional, default=0\n",
    "    * 양수로 주어지는 경우, 데이터로더가 데이터를 불러오는 제한시간\n",
    "* ## worker_init_fn\n",
    "    * callable, optioinal, default='None'\n",
    "    * 어떤 worker를 불러올지 리스트로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7a31570",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self, name='mlp', xdim=28*28, hdim=256, ydim=10):\n",
    "        super(MNIST_MLP, self).__init__() # 부모 클래스의 속성을 가져오기 위해 명시\n",
    "        self.name = name\n",
    "        self.xdim = xdim\n",
    "        self.hdim = hdim\n",
    "        self.ydim = ydim\n",
    "        \n",
    "        self.lin_1 = nn.Linear(self.xdim, self.hdim)\n",
    "        self.lin_2 = nn.Linear(self.hdim, self.ydim) \n",
    "#         self.lin_2 = nn.Linear(self.hdim, 100)\n",
    "#         self.lin_3 = nn.Linear(100, self.ydim)\n",
    "#         self.layers = [self.lin_1, self.lin_2, self.lin_3]\n",
    "        self.layers = [self.lin_1, self.lin_2]\n",
    "\n",
    "        self.net = nn.Sequential()\n",
    "        \n",
    "        for l_idx, layer in enumerate(self.layers):\n",
    "            layer_name = f'{type(layer).__name__.lower()}_{l_idx}'\n",
    "            self.net.add_module(layer_name, layer)\n",
    "            \n",
    "        self. init_param() # 파라미터 initialize\n",
    "        \n",
    "    def init_param(self):\n",
    "        nn.init.kaiming_normal_(self.lin_1.weight)\n",
    "        nn.init.zeros_(self.lin_1.bias)\n",
    "        nn.init.kaiming_normal_(self.lin_2.weight)\n",
    "        nn.init.zeros_(self.lin_2.bias)\n",
    "#         nn.init.kaiming_normal_(self.lin_3.weight)\n",
    "#         nn.init.zeros_(self.lin_3.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "442af965",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = MNIST_MLP(name='mlp', xdim=28*28, hdim=256, ydim=10).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optm = optim.Adam(M.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a047c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        n_total, n_correct = 0, 0\n",
    "        for batch_in, batch_out in data_iter:\n",
    "            y_trgt = batch_out.to(device)\n",
    "            model_pred = model(batch_in.view(-1, 28*28).to(device))\n",
    "            _, y_pred = torch.max(model_pred.data, 1)\n",
    "            n_correct += (y_pred==y_trgt).sum().item()\n",
    "            n_total += batch_in.size(0)\n",
    "        val_accr = (n_correct/n_total)\n",
    "        model.train()\n",
    "    return val_accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9871ae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accr : 0.101, test_accr : 0.104\n"
     ]
    }
   ],
   "source": [
    "M.init_param()\n",
    "train_accr = func_eval(M, train_iter, device)\n",
    "test_accr = func_eval(M, test_iter, device)\n",
    "print(f\"train_accr : {round(train_accr, 3)}, test_accr : {round(test_accr, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e902dbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jihoon\\anaconda3\\envs\\t200c117\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (256) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_in, batch_out \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mforward(batch_in\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m---> 10\u001b[0m     loss_out \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Update\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     optm\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\t200c117\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\t200c117\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\t200c117\\lib\\site-packages\\torch\\nn\\functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\t200c117\\lib\\site-packages\\torch\\functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (256) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print('Training Start')\n",
    "M.init_param()\n",
    "M.train()\n",
    "EPOCHS, print_every = 10, 1\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_val_sum = 0\n",
    "    for batch_in, batch_out in train_iter:\n",
    "        # Forward\n",
    "        y_pred = M.forward(batch_in.view(-1, 28*28).to(device))\n",
    "        loss_out = loss(y_pred, batch_out.to(device))\n",
    "        # Update\n",
    "        optm.zero_grad()\n",
    "        loss_out.backward()\n",
    "        optm.step()\n",
    "        loss_val_sum += loss_out\n",
    "    loss_val_avg = loss_val_sum/len(train_iter)\n",
    "    # Print\n",
    "    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
    "        train_accr = func_eval(M, train_iter, device)\n",
    "        test_accr = func_eval(M, test_iter, device)\n",
    "        \n",
    "        print(f\"epoch : {epoch}\")\n",
    "        print(f\"loss : {loss_val_avg}, train_accr : {round(train_accr, 3)}, test_accr : {round(test_accr, 3)}\")\n",
    "print(f\"{'-'*30}\")\n",
    "print('Training End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693368ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch 2.0.0, cuda 11.7",
   "language": "python",
   "name": "t200c117"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
